END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_DEFAULT
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_DEFAULT
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 67ca54bd_DEFAULT
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_DEFAULT
END: Invoking DEFAULT controller pipeline for event InstanceConfigChange::67ca54bd_DEFAULT for cluster QuickStartCluster, took 63 ms
Callback time for event: InstanceConfigChange took: 0 ms
InQueue time for event: InstanceConfigChange took: 25 ms
TotalProcessed time for event: InstanceConfigChange took: 63 ms
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: MessageChange  8ff37168_DEFAULT
Event 8ff37168_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Event 8ff37168_DEFAULT : No ideal state change for QuickStartCluster cluster, DEFAULT pipeline
Event 8ff37168_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event QuickStartCluster::TASK::67ca54bd_TASK : 0 properties refreshed from ZK.
Event QuickStartCluster::TASK::67ca54bd_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325186583, took 24 ms
Event QuickStartCluster::DEFAULT::8ff37168_DEFAULT : 1 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::8ff37168_DEFAULT : Refreshed 3 property InstanceConfig took 3 ms. Selective: true
Event 8ff37168_DEFAULT : Reloaded InstanceConfig for cluster QuickStartCluster, DEFAULT pipeline. Keys: [Broker_172.19.0.2_8000, Server_172.19.0.2_7000, Controller_172.19.0.2_9000]
Event 8ff37168_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event 67ca54bd_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325186554 took 61 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 62 ms for event 67ca54bd_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_TASK
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_TASK
START TaskPersistDataStage.process()
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_TASK
START AsyncProcess: TASK::TaskGarbageCollectionStage
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 0 ms
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_TASK
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 67ca54bd_TASK
END: Invoking TASK controller pipeline for event InstanceConfigChange::67ca54bd_TASK for cluster QuickStartCluster, took 64 ms
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: MessageChange  8ff37168_TASK
Event 8ff37168_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
Event 8ff37168_TASK : No ideal state change for QuickStartCluster cluster, TASK pipeline
Event 8ff37168_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
Event QuickStartCluster::TASK::8ff37168_TASK : 0 properties refreshed from ZK.
Event QuickStartCluster::TASK::8ff37168_TASK : Refreshed 3 property InstanceConfig took 1 ms. Selective: true
Event 8ff37168_TASK : Reloaded InstanceConfig for cluster QuickStartCluster, TASK pipeline. Keys: [Broker_172.19.0.2_8000, Server_172.19.0.2_7000, Controller_172.19.0.2_9000]
Event 8ff37168_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
Event QuickStartCluster::DEFAULT::8ff37168_DEFAULT : Refreshed 8 property StateModelDefinition took 22 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::8ff37168_DEFAULT : Refreshed 1 property ClusterConstraint took 2 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
Event QuickStartCluster::DEFAULT::8ff37168_DEFAULT : 0 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::8ff37168_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325186637, took 2 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event 8ff37168_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325186606 took 33 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 34 ms for event 8ff37168_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
Computing BestPossibleMapping for brokerResource
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 8ff37168_DEFAULT
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 0 ms
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_DEFAULT
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 2 ms
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 2 ms for event 8ff37168_DEFAULT
END: Invoking DEFAULT controller pipeline for event MessageChange::8ff37168_DEFAULT for cluster QuickStartCluster, took 38 ms
Callback time for event: MessageChange took: 1 ms
InQueue time for event: MessageChange took: 58 ms
TotalProcessed time for event: MessageChange took: 38 ms
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: InstanceConfigChange  f3d5e070_DEFAULT
Event f3d5e070_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Event f3d5e070_DEFAULT : No ideal state change for QuickStartCluster cluster, DEFAULT pipeline
Event f3d5e070_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event f3d5e070_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event f3d5e070_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
Event QuickStartCluster::TASK::8ff37168_TASK : Refreshed 8 property StateModelDefinition took 24 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::8ff37168_TASK : Refreshed 1 property ClusterConstraint took 6 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
Event QuickStartCluster::TASK::8ff37168_TASK : 0 properties refreshed from ZK.
Event QuickStartCluster::TASK::8ff37168_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325186654, took 3 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event 8ff37168_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325186621 took 37 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 37 ms for event 8ff37168_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_TASK
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_TASK
START TaskPersistDataStage.process()
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_TASK
START AsyncProcess: TASK::TaskGarbageCollectionStage
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 0 ms
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 1 ms for event 8ff37168_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_TASK
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8ff37168_TASK
END: Invoking TASK controller pipeline for event MessageChange::8ff37168_TASK for cluster QuickStartCluster, took 42 ms
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: InstanceConfigChange  f3d5e070_TASK
Event f3d5e070_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
Event f3d5e070_TASK : No ideal state change for QuickStartCluster cluster, TASK pipeline
Event f3d5e070_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
Event f3d5e070_TASK : No instance config change for QuickStartCluster cluster, TASK pipeline
Event f3d5e070_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
Event QuickStartCluster::DEFAULT::f3d5e070_DEFAULT : Refreshed 8 property StateModelDefinition took 29 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::f3d5e070_DEFAULT : Refreshed 1 property ClusterConstraint took 3 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 2 ms. 
Event QuickStartCluster::TASK::f3d5e070_TASK : Refreshed 8 property StateModelDefinition took 17 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::f3d5e070_TASK : Refreshed 1 property ClusterConstraint took 2 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
Event QuickStartCluster::TASK::f3d5e070_TASK : 0 properties refreshed from ZK.
Event QuickStartCluster::TASK::f3d5e070_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325186688, took 2 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event f3d5e070_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325186667 took 24 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 24 ms for event f3d5e070_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_TASK
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_TASK
START TaskPersistDataStage.process()
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_TASK
START AsyncProcess: TASK::TaskGarbageCollectionStage
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 0 ms
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 1 ms for event f3d5e070_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_TASK
Event QuickStartCluster::DEFAULT::f3d5e070_DEFAULT : 0 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::f3d5e070_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325186682, took 11 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event f3d5e070_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325186647 took 46 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 46 ms for event f3d5e070_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event f3d5e070_DEFAULT
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 1 ms for event f3d5e070_TASK
END: Invoking TASK controller pipeline for event InstanceConfigChange::f3d5e070_TASK for cluster QuickStartCluster, took 27 ms
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 0 ms
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f3d5e070_DEFAULT
END: Invoking DEFAULT controller pipeline for event InstanceConfigChange::f3d5e070_DEFAULT for cluster QuickStartCluster, took 48 ms
Callback time for event: InstanceConfigChange took: 1 ms
InQueue time for event: InstanceConfigChange took: 90 ms
TotalProcessed time for event: InstanceConfigChange took: 48 ms
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:setData cxid:0x240 zxid:0x142 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/PROPERTYSTORE/SCHEMAS/meetupRsvp Error:KeeperErrorCode = NoNode for /QuickStartCluster/PROPERTYSTORE/SCHEMAS/meetupRsvp
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:create cxid:0x241 zxid:0x143 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/PROPERTYSTORE/SCHEMAS Error:KeeperErrorCode = NoNode for /QuickStartCluster/PROPERTYSTORE/SCHEMAS
Notifying metadata event for adding new schema meetupRsvp
Handled request from 172.19.0.2 POST http://8012e79c96b0:9000/schemas, content-type multipart/form-data; boundary=sMsw2NjGQM2j4neeaaU-qKHgGyBqTUNNACPtzcCv status code 200 OK
Sending request: http://8012e79c96b0:9000/schemas to controller: 8012e79c96b0, version: Unknown
Validating table configs for Table: meetupRsvp
Table: meetupRsvp is not a hybrid table. Skipping consistency check across realtime and offline parts of the table.
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:setData cxid:0x255 zxid:0x146 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE/meetupRsvp_REALTIME Error:KeeperErrorCode = NoNode for /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE/meetupRsvp_REALTIME
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:create cxid:0x256 zxid:0x147 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE Error:KeeperErrorCode = NoNode for /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
PinotRealtimeSegmentManager.handleChildChange: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
Processing change notification for path: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
Received change notification for path: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
PinotRealtimeSegmentManager.handleDataChange: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
Processing change notification for path: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
Received change notification for path: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
PinotRealtimeSegmentManager.handleChildChange: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
Processing change notification for path: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
Received change notification for path: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE
Setting data/child changes watch for real-time table 'meetupRsvp_REALTIME'
Initializing IdealState for HLC table: meetupRsvp_REALTIME
PinotRealtimeSegmentManager.handleChildChange with table: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE/meetupRsvp_REALTIME
Processing change notification for path: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE/meetupRsvp_REALTIME
Received change notification for path: /QuickStartCluster/PROPERTYSTORE/CONFIGS/TABLE/meetupRsvp_REALTIME
Setting data/child changes watch for real-time table 'meetupRsvp_REALTIME'
Computed list of new segments to add : []
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:setData cxid:0x26e zxid:0x14a txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/PROPERTYSTORE/CONFIGS/INSTANCE/Server_172.19.0.2_7000 Error:KeeperErrorCode = NoNode for /QuickStartCluster/PROPERTYSTORE/CONFIGS/INSTANCE/Server_172.19.0.2_7000
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:create cxid:0x26f zxid:0x14b txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/PROPERTYSTORE/CONFIGS/INSTANCE Error:KeeperErrorCode = NoNode for /QuickStartCluster/PROPERTYSTORE/CONFIGS/INSTANCE
Add resource meetupRsvp_REALTIME in cluster QuickStartCluster.
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:create cxid:0x274 zxid:0x14e txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/IDEALSTATES Error:KeeperErrorCode = NodeExists for /QuickStartCluster/IDEALSTATES
Subscribing changes listener to path: /QuickStartCluster/IDEALSTATES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/IDEALSTATES
Subscribing data change listener to all children for path:/QuickStartCluster/IDEALSTATES
Creating property store entry for HLC table: meetupRsvp_REALTIME
Subscribing to path:/QuickStartCluster/IDEALSTATES took:8
103 START:INVOKE /QuickStartCluster/IDEALSTATES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
Resubscribe change listener to path: /QuickStartCluster/IDEALSTATES, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/IDEALSTATES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/IDEALSTATES
Subscribing data change listener to all children for path:/QuickStartCluster/IDEALSTATES
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:create cxid:0x277 zxid:0x150 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/PROPERTYSTORE/SEGMENTS Error:KeeperErrorCode = NoNode for /QuickStartCluster/PROPERTYSTORE/SEGMENTS
START: Generic GenericClusterController.onIdealStateChange() for cluster QuickStartCluster
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: IdealStateChange  a8b55bb5_TASK
Event a8b55bb5_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: IdealStateChange  a8b55bb5_DEFAULT
Event a8b55bb5_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Event QuickStartCluster::DEFAULT::a8b55bb5_DEFAULT : 1 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::a8b55bb5_DEFAULT : Refreshed 3 property IdealState took 10 ms. Selective: true
Event a8b55bb5_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event a8b55bb5_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event a8b55bb5_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
Successfully added or updated the table meetupRsvp_REALTIME 
Updating BrokerResource IdealState for table: meetupRsvp_REALTIME
PinotRealtimeSegmentManager.handleChildChange: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
Processing change notification for path: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
Received change notification for path: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
Event QuickStartCluster::TASK::a8b55bb5_TASK : 1 properties refreshed from ZK.
Event QuickStartCluster::TASK::a8b55bb5_TASK : Refreshed 3 property IdealState took 15 ms. Selective: true
Event a8b55bb5_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
Event a8b55bb5_TASK : No instance config change for QuickStartCluster cluster, TASK pipeline
Event a8b55bb5_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
Subscribing to path:/QuickStartCluster/IDEALSTATES took:17
Setting data/child changes watch for real-time table 'meetupRsvp_REALTIME'
Controller stopping periodical rebalance timer at period 9223372036854775807
END: GenericClusterController.onIdealStateChange() for cluster QuickStartCluster
103 END:INVOKE /QuickStartCluster/IDEALSTATES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 37ms
Event QuickStartCluster::DEFAULT::a8b55bb5_DEFAULT : Refreshed 8 property StateModelDefinition took 30 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::a8b55bb5_DEFAULT : Refreshed 1 property ClusterConstraint took 3 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
Event QuickStartCluster::DEFAULT::a8b55bb5_DEFAULT : 0 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::a8b55bb5_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187159, took 2 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event a8b55bb5_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187112 took 50 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 50 ms for event a8b55bb5_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
Computing BestPossibleMapping for meetupRsvp_REALTIME
Computing BestPossibleMapping for brokerResource
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
Event QuickStartCluster::TASK::a8b55bb5_TASK : Refreshed 8 property StateModelDefinition took 36 ms. Selective: false
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 2 ms for event a8b55bb5_DEFAULT
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event a8b55bb5_DEFAULT
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 0 ms
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::a8b55bb5_TASK : Refreshed 1 property ClusterConstraint took 3 ms. Selective: false
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
START: InstanceMessagesCache.refresh()
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_DEFAULT
END: Invoking DEFAULT controller pipeline for event IdealStateChange::a8b55bb5_DEFAULT for cluster QuickStartCluster, took 58 ms
Callback time for event: IdealStateChange took: 10 ms
InQueue time for event: IdealStateChange took: 4 ms
TotalProcessed time for event: IdealStateChange took: 58 ms
103 START:INVOKE /QuickStartCluster/IDEALSTATES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: Generic GenericClusterController.onIdealStateChange() for cluster QuickStartCluster
Resubscribe change listener to path: /QuickStartCluster/IDEALSTATES, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/IDEALSTATES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/IDEALSTATES
Handled request from 172.19.0.2 POST http://8012e79c96b0:9000/tables, content-type application/x-www-form-urlencoded status code 200 OK
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: IdealStateChange  0de31153_DEFAULT
Event 0de31153_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Subscribing data change listener to all children for path:/QuickStartCluster/IDEALSTATES
Controller stopping periodical rebalance timer at period 9223372036854775807
END: GenericClusterController.onIdealStateChange() for cluster QuickStartCluster
103 END:INVOKE /QuickStartCluster/IDEALSTATES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 4ms
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 8 ms. 
Computed list of new segments to add : [first=meetupRsvp_REALTIME_1608325187082_0__0__1608325187180, second=Server_172.19.0.2_7000]
Event QuickStartCluster::TASK::a8b55bb5_TASK : 0 properties refreshed from ZK.
Event QuickStartCluster::TASK::a8b55bb5_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187178, took 10 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event a8b55bb5_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187111 took 78 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 79 ms for event a8b55bb5_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_TASK
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_TASK
START TaskPersistDataStage.process()
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_TASK
Got user-level KeeperException when processing sessionid:0x10011325aa60004 type:setData cxid:0x28c zxid:0x154 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME/meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 Error:KeeperErrorCode = NoNode for /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME/meetupRsvp_REALTIME_1608325187082_0__0__1608325187180
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 10 ms for event a8b55bb5_TASK
START AsyncProcess: TASK::TaskGarbageCollectionStage
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_TASK
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 0 ms
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a8b55bb5_TASK
END: Invoking TASK controller pipeline for event IdealStateChange::a8b55bb5_TASK for cluster QuickStartCluster, took 90 ms
{"status":"Table meetupRsvp_REALTIME succesfully added"}
[36m***** Waiting for 5 seconds for a few events to get populated *****[0m
Subscribing to path:/QuickStartCluster/IDEALSTATES took:31
Event QuickStartCluster::DEFAULT::0de31153_DEFAULT : 1 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::0de31153_DEFAULT : Refreshed 3 property IdealState took 29 ms. Selective: true
Event 0de31153_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event 0de31153_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event 0de31153_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: IdealStateChange  0de31153_TASK
Event 0de31153_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
PinotRealtimeSegmentManager.handleDataChange: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
Processing change notification for path: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
Received change notification for path: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
Setting data/child changes watch for real-time table 'meetupRsvp_REALTIME'
103 START:INVOKE /QuickStartCluster/IDEALSTATES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: Generic GenericClusterController.onIdealStateChange() for cluster QuickStartCluster
Resubscribe change listener to path: /QuickStartCluster/IDEALSTATES, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/IDEALSTATES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/IDEALSTATES
Setting data change watch for real-time segment currently being consumed: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME/meetupRsvp_REALTIME_1608325187082_0__0__1608325187180
Event QuickStartCluster::TASK::0de31153_TASK : 2 properties refreshed from ZK.
Event QuickStartCluster::TASK::0de31153_TASK : Refreshed 3 property IdealState took 16 ms. Selective: true
Event 0de31153_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
Event 0de31153_TASK : No instance config change for QuickStartCluster cluster, TASK pipeline
Event 0de31153_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
Controller stopping periodical rebalance timer at period 9223372036854775807
END: GenericClusterController.onIdealStateChange() for cluster QuickStartCluster
103 END:INVOKE /QuickStartCluster/IDEALSTATES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 7ms
Subscribing data change listener to all children for path:/QuickStartCluster/IDEALSTATES
Subscribing to path:/QuickStartCluster/IDEALSTATES took:17
Event QuickStartCluster::DEFAULT::0de31153_DEFAULT : Refreshed 8 property StateModelDefinition took 35 ms. Selective: false
Event QuickStartCluster::TASK::0de31153_TASK : Refreshed 8 property StateModelDefinition took 20 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Computed list of new segments to add : []
Event QuickStartCluster::DEFAULT::0de31153_DEFAULT : Refreshed 1 property ClusterConstraint took 9 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::0de31153_TASK : Refreshed 1 property ClusterConstraint took 6 ms. Selective: false
Event QuickStartCluster::DEFAULT::0de31153_DEFAULT : 0 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::0de31153_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187251, took 3 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event 0de31153_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187176 took 78 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 78 ms for event 0de31153_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
Event 0de31153_DEFAULT : Cannot confirm top state missing start time. Use the current system time as the start time.
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 0de31153_DEFAULT
Computing BestPossibleMapping for meetupRsvp_REALTIME
Computing BestPossibleMapping for brokerResource
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 1 ms
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
Register MBean: ClusterStatus:cluster=QuickStartCluster,instanceName=Broker_172.19.0.2_8000,resourceName=brokerResource
PinotRealtimeSegmentManager.handleChildChange: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
Processing change notification for path: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
START: InstanceMessagesCache.refresh()
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 0de31153_DEFAULT
Received change notification for path: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME
Event 0de31153_DEFAULT : Sending Message c312b87e-96cc-4b27-9cdc-0d542d93bf3c to Broker_172.19.0.2_8000 transit brokerResource.meetupRsvp_REALTIME|[] from:OFFLINE to:ONLINE, relayMessages: 0
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 3 ms for event 0de31153_DEFAULT
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, type: CALLBACK, listener: org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_DEFAULT
END: Invoking DEFAULT controller pipeline for event IdealStateChange::0de31153_DEFAULT for cluster QuickStartCluster, took 86 ms
Callback time for event: IdealStateChange took: 0 ms
InQueue time for event: IdealStateChange took: 3 ms
TotalProcessed time for event: IdealStateChange took: 86 ms
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES took:1
103 START:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES took:1
216 START:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES listener:org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e type: CALLBACK
START: GenericClusterController.onMessage() for cluster QuickStartCluster
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: false
END: GenericClusterController.onMessage() for cluster QuickStartCluster
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES
103 END:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 1ms
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES took:1
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, for listener: org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e, watchChild: false
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, type: CALLBACK, listener: org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: IdealStateChange  8edf5691_DEFAULT
Event 8edf5691_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES took:2
The latency of message c312b87e-96cc-4b27-9cdc-0d542d93bf3c is 10 ms
Setting data/child changes watch for real-time table 'meetupRsvp_REALTIME'
Got user-level KeeperException when processing sessionid:0x10011325aa60007 type:create cxid:0xdc zxid:0x158 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 Error:KeeperErrorCode = NoNode for /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 took:3
103 START:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: GenericClusterController.onStateChange()
END: GenericClusterController.onStateChange()
103 END:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 1ms
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Event QuickStartCluster::DEFAULT::8edf5691_DEFAULT : 1 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::8edf5691_DEFAULT : Refreshed 3 property IdealState took 13 ms. Selective: true
Event 8edf5691_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event 8edf5691_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event 8edf5691_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
END: InstanceMessagesCache.refresh(), 1 of Messages read from ZooKeeper. took 23 ms. 
Setting data change watch for real-time segment currently being consumed: /QuickStartCluster/PROPERTYSTORE/SEGMENTS/meetupRsvp_REALTIME/meetupRsvp_REALTIME_1608325187082_0__0__1608325187180
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 took:7
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 took:6
103 START:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: GenericClusterController.onStateChange()
END: GenericClusterController.onStateChange()
103 END:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 1ms
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 took:4
No config found at /QuickStartCluster/CONFIGS/RESOURCE/brokerResource
Scheduling message c312b87e-96cc-4b27-9cdc-0d542d93bf3c: brokerResource:meetupRsvp_REALTIME, OFFLINE->ONLINE
Submit task: c312b87e-96cc-4b27-9cdc-0d542d93bf3c to pool: java.util.concurrent.ThreadPoolExecutor@28c6308d[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
Event QuickStartCluster::TASK::0de31153_TASK : 1 properties refreshed from ZK.
Event QuickStartCluster::TASK::0de31153_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187282, took 13 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event 0de31153_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187207 took 89 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 89 ms for event 0de31153_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_TASK
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 1 ms for event 0de31153_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_TASK
START TaskPersistDataStage.process()
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_TASK
Event QuickStartCluster::DEFAULT::8edf5691_DEFAULT : Refreshed 8 property StateModelDefinition took 21 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::8edf5691_DEFAULT : Refreshed 1 property ClusterConstraint took 3 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
Event QuickStartCluster::DEFAULT::8edf5691_DEFAULT : 1 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::8edf5691_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187304, took 5 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
START AsyncProcess: TASK::TaskGarbageCollectionStage
handling task: c312b87e-96cc-4b27-9cdc-0d542d93bf3c begin, at: 1608325187309
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
Message: c312b87e-96cc-4b27-9cdc-0d542d93bf3c handling task scheduled
216 END:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES listener:org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e type: CALLBACK Took: 47ms
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 13 ms for event 0de31153_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_TASK
handling message: c312b87e-96cc-4b27-9cdc-0d542d93bf3c transit brokerResource.meetupRsvp_REALTIME|[] from:OFFLINE to:ONLINE, relayedFrom: null
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 1 ms
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 0de31153_TASK
END: Invoking TASK controller pipeline for event IdealStateChange::0de31153_TASK for cluster QuickStartCluster, took 103 ms
Event 8edf5691_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187265 took 45 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 48 ms for event 8edf5691_DEFAULT
Controller stopping periodical rebalance timer at period 9223372036854775807
Merging with delta list, recordId = brokerResource other:brokerResource
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: IdealStateChange  8edf5691_TASK
Event 8edf5691_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_DEFAULT
Removed /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007/brokerResource
Instance Broker_172.19.0.2_8000, partition meetupRsvp_REALTIME received state transition from OFFLINE to ONLINE on session 10011325aa60007, message id: c312b87e-96cc-4b27-9cdc-0d542d93bf3c
Processing transition from OFFLINE to ONLINE for table: meetupRsvp_REALTIME
Building routing for table: meetupRsvp_REALTIME
172.19.0.2_9000 unsubscribe data-change. path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007/brokerResource, listener: org.apache.helix.controller.GenericHelixController@553bc36c
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 8edf5691_DEFAULT
Event 8edf5691_DEFAULT : Cannot confirm top state missing start time. Use the current system time as the start time.
172.19.0.2_9000 unsubscribe child-change. path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007/brokerResource, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Event QuickStartCluster::TASK::8edf5691_TASK : 0 properties refreshed from ZK.
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 8edf5691_DEFAULT
Computing BestPossibleMapping for meetupRsvp_REALTIME
Computing BestPossibleMapping for brokerResource
Computing IdealState for leadControllerResource
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
Event QuickStartCluster::TASK::8edf5691_TASK : Refreshed 3 property IdealState took 4 ms. Selective: true
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 took:2
103 START:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: GenericClusterController.onStateChange()
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 2 ms for event 8edf5691_DEFAULT
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Register MBean: ClusterStatus:cluster=QuickStartCluster,instanceName=Server_172.19.0.2_7000,resourceName=meetupRsvp_REALTIME
END: GenericClusterController.onStateChange()
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 8edf5691_DEFAULT
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Event 8edf5691_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
103 END:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 0ms
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 1 ms
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 8edf5691_DEFAULT
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Event 8edf5691_DEFAULT : Message already exists for Broker_172.19.0.2_8000 to transit brokerResource.meetupRsvp_REALTIME from OFFLINE to ONLINE, isRelay: false
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_DEFAULT
Event 8edf5691_TASK : No instance config change for QuickStartCluster cluster, TASK pipeline
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 took:3
Event 8edf5691_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_DEFAULT
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_DEFAULT
Event 8edf5691_DEFAULT : Sending Message dd3a69d3-87ca-40de-b26a-4af6dc322a80 to Server_172.19.0.2_7000 transit meetupRsvp_REALTIME.meetupRsvp_REALTIME_1608325187082_0__0__1608325187180|[] from:OFFLINE to:ONLINE, relayMessages: 0
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 6 ms for event 8edf5691_DEFAULT
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, type: CALLBACK, listener: org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 8edf5691_DEFAULT
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES took:1
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
226 START:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES listener:org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea type: CALLBACK
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_DEFAULT
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, for listener: org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea, watchChild: false
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, type: CALLBACK, listener: org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES
END: Invoking DEFAULT controller pipeline for event IdealStateChange::8edf5691_DEFAULT for cluster QuickStartCluster, took 64 ms
Callback time for event: IdealStateChange took: 1 ms
InQueue time for event: IdealStateChange took: 44 ms
TotalProcessed time for event: IdealStateChange took: 64 ms
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES took:1
Computed list of new segments to add : []
Built routing for table: meetupRsvp_REALTIME
The latency of message dd3a69d3-87ca-40de-b26a-4af6dc322a80 is 12 ms
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES took:4
103 START:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: false
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES
START: GenericClusterController.onMessage() for cluster QuickStartCluster
END: GenericClusterController.onMessage() for cluster QuickStartCluster
103 END:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 1ms
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: MessageChange  74cfea56_DEFAULT
Event 74cfea56_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Event 74cfea56_DEFAULT : No ideal state change for QuickStartCluster cluster, DEFAULT pipeline
Event 74cfea56_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES took:2
Event 74cfea56_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event 74cfea56_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
Got user-level KeeperException when processing sessionid:0x10011325aa60008 type:create cxid:0x129 zxid:0x15e txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 Error:KeeperErrorCode = NoNode for /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Initializing rate limiter for table meetupRsvp_REALTIME
No qps config specified for table: meetupRsvp_REALTIME
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 took:1
103 START:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: GenericClusterController.onStateChange()
END: GenericClusterController.onStateChange()
103 END:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 0ms
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 took:1
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 took:4
103 START:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: GenericClusterController.onStateChange()
END: GenericClusterController.onStateChange()
103 END:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 0ms
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 took:3
Got user-level KeeperException when processing sessionid:0x10011325aa60007 type:setData cxid:0xf2 zxid:0x161 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007/brokerResource Error:KeeperErrorCode = NoNode for /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007/brokerResource
Message c312b87e-96cc-4b27-9cdc-0d542d93bf3c completed.
Delete message c312b87e-96cc-4b27-9cdc-0d542d93bf3c from zk!
MBean CLMParticipantReport:Cluster=QuickStartCluster,Transition=OFFLINE--ONLINE has been registered.
message finished: c312b87e-96cc-4b27-9cdc-0d542d93bf3c, took 53
Message: c312b87e-96cc-4b27-9cdc-0d542d93bf3c (parent: null) handling task for brokerResource:meetupRsvp_REALTIME completed at: 1608325187362, results: true. FrameworkTime: 3 ms; HandlerTime: 50 ms.
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, type: CALLBACK, listener: org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES took:1
216 START:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES listener:org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e type: CALLBACK
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, for listener: org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e, watchChild: false
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, type: CALLBACK, listener: org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES
No Messages to process
216 END:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES listener:org.apache.helix.messaging.handling.HelixTaskExecutor@3a205a4e type: CALLBACK Took: 0ms
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES took:0
No config found at /QuickStartCluster/CONFIGS/RESOURCE/meetupRsvp_REALTIME
Scheduling message dd3a69d3-87ca-40de-b26a-4af6dc322a80: meetupRsvp_REALTIME:meetupRsvp_REALTIME_1608325187082_0__0__1608325187180, OFFLINE->ONLINE
Submit task: dd3a69d3-87ca-40de-b26a-4af6dc322a80 to pool: java.util.concurrent.ThreadPoolExecutor@3b1ebb66[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 took:5
103 START:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
Event QuickStartCluster::DEFAULT::74cfea56_DEFAULT : Refreshed 8 property StateModelDefinition took 34 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::74cfea56_DEFAULT : Refreshed 1 property ClusterConstraint took 2 ms. Selective: false
START: InstanceMessagesCache.refresh()
Message: dd3a69d3-87ca-40de-b26a-4af6dc322a80 handling task scheduled
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
226 END:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES listener:org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea type: CALLBACK Took: 46ms
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
handling task: dd3a69d3-87ca-40de-b26a-4af6dc322a80 begin, at: 1608325187375
START: GenericClusterController.onStateChange()
END: GenericClusterController.onStateChange()
103 END:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 8ms
handling message: dd3a69d3-87ca-40de-b26a-4af6dc322a80 transit meetupRsvp_REALTIME.meetupRsvp_REALTIME_1608325187082_0__0__1608325187180|[] from:OFFLINE to:ONLINE, relayedFrom: null
Event QuickStartCluster::TASK::8edf5691_TASK : Refreshed 8 property StateModelDefinition took 57 ms. Selective: false
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 7 ms. 
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES took:1
103 START:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: GenericClusterController.onMessage() for cluster QuickStartCluster
END: GenericClusterController.onMessage() for cluster QuickStartCluster
103 END:INVOKE /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 0ms
Merging with delta list, recordId = meetupRsvp_REALTIME other:meetupRsvp_REALTIME
Removed /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008/meetupRsvp_REALTIME
Instance Server_172.19.0.2_7000, partition meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 received state transition from OFFLINE to ONLINE on session 10011325aa60008, message id: dd3a69d3-87ca-40de-b26a-4af6dc322a80
SegmentOnlineOfflineStateModel.onBecomeOnlineFromOffline() : ZnRecord=dd3a69d3-87ca-40de-b26a-4af6dc322a80, {CREATE_TIMESTAMP=1608325187321, ClusterEventName=IdealStateChange, EXECUTE_START_TIMESTAMP=1608325187375, EXE_SESSION_ID=10011325aa60008, FROM_STATE=OFFLINE, MSG_ID=dd3a69d3-87ca-40de-b26a-4af6dc322a80, MSG_STATE=read, MSG_TYPE=STATE_TRANSITION, PARTITION_NAME=meetupRsvp_REALTIME_1608325187082_0__0__1608325187180, READ_TIMESTAMP=1608325187337, RESOURCE_NAME=meetupRsvp_REALTIME, RESOURCE_TAG=meetupRsvp_REALTIME, SRC_NAME=172.19.0.2_9000, SRC_SESSION_ID=10011325aa60002, STATE_MODEL_DEF=SegmentOnlineOfflineStateModel, STATE_MODEL_FACTORY_NAME=DEFAULT, TGT_NAME=Server_172.19.0.2_7000, TGT_SESSION_ID=10011325aa60008, TO_STATE=ONLINE}{}{}, Stat=Stat {_version=0, _creationTime=1608325187326, _modifiedTime=1608325187326, _ephemeralOwner=0}
Adding segment: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 to table: meetupRsvp_REALTIME
172.19.0.2_9000 unsubscribe data-change. path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008/meetupRsvp_REALTIME, listener: org.apache.helix.controller.GenericHelixController@553bc36c
172.19.0.2_9000 unsubscribe child-change. path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008/meetupRsvp_REALTIME, listener: org.apache.helix.controller.GenericHelixController@553bc36c
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::8edf5691_TASK : Refreshed 1 property ClusterConstraint took 5 ms. Selective: false
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/CURRENTSTATES/10011325aa60007 took:10
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: false
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES
START: InstanceMessagesCache.refresh()
Creating table data manager for table: meetupRsvp_REALTIME
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing to path:/QuickStartCluster/INSTANCES/Broker_172.19.0.2_8000/MESSAGES took:4
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 took:1
103 START:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: GenericClusterController.onStateChange()
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
END: GenericClusterController.onStateChange()
103 END:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 0ms
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 took:1
Event QuickStartCluster::DEFAULT::74cfea56_DEFAULT : 1 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::74cfea56_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187381, took 11 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event 74cfea56_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187336 took 56 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 57 ms for event 74cfea56_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
Event 74cfea56_DEFAULT : Missing top state duration is 56/89 (helix latency / end to end latency) for partition meetupRsvp_REALTIME. Graceful: true
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 74cfea56_DEFAULT
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 74cfea56_DEFAULT
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 0 ms
Event 74cfea56_DEFAULT : Message already exists for Server_172.19.0.2_7000 to transit meetupRsvp_REALTIME.meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 from OFFLINE to ONLINE, isRelay: false
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 74cfea56_DEFAULT
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event 74cfea56_DEFAULT
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event 74cfea56_DEFAULT
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
END: Invoking DEFAULT controller pipeline for event MessageChange::74cfea56_DEFAULT for cluster QuickStartCluster, took 61 ms
Callback time for event: MessageChange took: 2 ms
InQueue time for event: MessageChange took: 73 ms
TotalProcessed time for event: MessageChange took: 61 ms
END: InstanceMessagesCache.refresh(), 1 of Messages read from ZooKeeper. took 15 ms. 
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: CurrentStateChange  f37fa058_DEFAULT
Event f37fa058_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Event f37fa058_DEFAULT : No ideal state change for QuickStartCluster cluster, DEFAULT pipeline
Event f37fa058_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event f37fa058_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event f37fa058_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
Event QuickStartCluster::TASK::8edf5691_TASK : 1 properties refreshed from ZK.
Event QuickStartCluster::TASK::8edf5691_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187401, took 8 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event 8edf5691_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187313 took 98 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 98 ms for event 8edf5691_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_TASK
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_TASK
START TaskPersistDataStage.process()
Initializing table data manager for table: meetupRsvp_REALTIME
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 1 ms for event 8edf5691_TASK
START AsyncProcess: TASK::TaskGarbageCollectionStage
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 0 ms
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_TASK
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event 8edf5691_TASK
END: Invoking TASK controller pipeline for event IdealStateChange::8edf5691_TASK for cluster QuickStartCluster, took 99 ms
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: MessageChange  a865fa4c_TASK
Event a865fa4c_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
Event a865fa4c_TASK : No ideal state change for QuickStartCluster cluster, TASK pipeline
Event a865fa4c_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
Event a865fa4c_TASK : No instance config change for QuickStartCluster cluster, TASK pipeline
Event a865fa4c_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
Initialized table data manager for table: meetupRsvp_REALTIME with data directory: /tmp/1608325154994/meetupRsvp/rawdata/PinotServerDataDir0/meetupRsvp_REALTIME
Starting table data manager for table: meetupRsvp_REALTIME
Started table data manager for table: meetupRsvp_REALTIME
Created table data manager for table: meetupRsvp_REALTIME
Event QuickStartCluster::DEFAULT::f37fa058_DEFAULT : Refreshed 8 property StateModelDefinition took 32 ms. Selective: false
Event QuickStartCluster::TASK::a865fa4c_TASK : Refreshed 8 property StateModelDefinition took 22 ms. Selective: false
RealtimeDataResourceZKMetadata contains no information about sorted column for segment meetupRsvp_REALTIME_1608325187082_0__0__1608325187180
Created segment data manager with Sorted column:null, invertedIndexColumns:[]
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::f37fa058_DEFAULT : Refreshed 1 property ClusterConstraint took 10 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::a865fa4c_TASK : Refreshed 1 property ClusterConstraint took 7 ms. Selective: false
START: InstanceMessagesCache.refresh()
Event QuickStartCluster::DEFAULT::f37fa058_DEFAULT : 0 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::f37fa058_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187446, took 2 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event f37fa058_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187401 took 47 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 47 ms for event f37fa058_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
Submitted asynchronous DEFAULT::ExternalViewComputeStage task to worker
END ExternalViewComputeStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
START AsyncProcess: DEFAULT::ExternalViewComputeStage
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
MBean ClusterStatus:cluster=QuickStartCluster,resourceName=meetupRsvp_REALTIME has been registered.
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 9 ms for event f37fa058_DEFAULT
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
Event f37fa058_DEFAULT : Message already exists for Server_172.19.0.2_7000 to transit meetupRsvp_REALTIME.meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 from OFFLINE to ONLINE, isRelay: false
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 0 ms
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_DEFAULT
END: Invoking DEFAULT controller pipeline for event CurrentStateChange::f37fa058_DEFAULT for cluster QuickStartCluster, took 58 ms
Callback time for event: CurrentStateChange took: 1 ms
InQueue time for event: CurrentStateChange took: 11 ms
TotalProcessed time for event: CurrentStateChange took: 58 ms
KafkaStreamLevelConsumer: streamConfig : StreamConfig{_type='kafka', _topicName='meetupRSVPEvents', _consumerTypes=[HIGHLEVEL], _consumerFactoryClassName='org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory', _offsetCriteria='OffsetCriteria{_offsetType=LARGEST, _offsetString='largest'}', _connectionTimeoutMillis=30000, _fetchTimeoutMillis=5000, _flushThresholdRows=5000000, _flushThresholdTimeMillis=21600000, _flushSegmentDesiredSizeBytes=209715200, _flushAutotuneInitialRows=100000, _decoderClass='org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder', _decoderProperties={}, _groupId='null, _tableNameWithType='meetupRsvp_REALTIME}
Creating new kafka consumer and iterator for topic meetupRSVPEvents
Got user-level KeeperException when processing sessionid:0x10011325aa60002 type:setData cxid:0xac2 zxid:0x166 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/EXTERNALVIEW/meetupRsvp_REALTIME Error:KeeperErrorCode = NoNode for /QuickStartCluster/EXTERNALVIEW/meetupRsvp_REALTIME
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: MessageChange  a865fa4c_DEFAULT
Event a865fa4c_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Event a865fa4c_DEFAULT : No ideal state change for QuickStartCluster cluster, DEFAULT pipeline
Event a865fa4c_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event a865fa4c_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event a865fa4c_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
195 START:INVOKE /QuickStartCluster/EXTERNALVIEW listener:org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93 type: CALLBACK
Resubscribe change listener to path: /QuickStartCluster/EXTERNALVIEW, for listener: org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/EXTERNALVIEW, type: CALLBACK, listener: org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93
Subscribing child change listener to path:/QuickStartCluster/EXTERNALVIEW
Enqueue EXTERNAL_VIEW change
195 END:INVOKE /QuickStartCluster/EXTERNALVIEW listener:org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93 type: CALLBACK Took: 1ms
Start processing EXTERNAL_VIEW change
Processing external view change
Subscribing data change listener to all children for path:/QuickStartCluster/EXTERNALVIEW
Processed external view change in 0ms (fetch 1 external view stats: 0ms, update routing entry for 0 tables ([]): 0ms)
Finish handling EXTERNAL_VIEW change for handler: org.apache.pinot.broker.routing.RoutingManager in 1ms
Start processing qps quota change.
Processed query quota change in 0ms, 0 out of 0 query quota configs rebuilt.
Finish handling EXTERNAL_VIEW change for handler: org.apache.pinot.broker.queryquota.HelixExternalViewBasedQueryQuotaManager in 2ms
Finish processing EXTERNAL_VIEW change in 3ms
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 27 ms. 
END AsyncProcess: DEFAULT::ExternalViewComputeStage, took 28 ms
ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:19092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = meetupRsvp_REALTIME_1608325187082_0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

Subscribing changes listener to path: /QuickStartCluster/EXTERNALVIEW, type: CALLBACK, listener: org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93
Subscribing child change listener to path:/QuickStartCluster/EXTERNALVIEW
Subscribing data change listener to all children for path:/QuickStartCluster/EXTERNALVIEW
Subscribing to path:/QuickStartCluster/EXTERNALVIEW took:12
Subscribing to path:/QuickStartCluster/EXTERNALVIEW took:10
195 START:INVOKE /QuickStartCluster/EXTERNALVIEW listener:org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93 type: CALLBACK
Enqueue EXTERNAL_VIEW change
195 END:INVOKE /QuickStartCluster/EXTERNALVIEW listener:org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93 type: CALLBACK Took: 0ms
Resubscribe change listener to path: /QuickStartCluster/EXTERNALVIEW, for listener: org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93, watchChild: true
Start processing EXTERNAL_VIEW change
Processing external view change
Subscribing changes listener to path: /QuickStartCluster/EXTERNALVIEW, type: CALLBACK, listener: org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93
Subscribing child change listener to path:/QuickStartCluster/EXTERNALVIEW
Subscribing data change listener to all children for path:/QuickStartCluster/EXTERNALVIEW
Event QuickStartCluster::DEFAULT::a865fa4c_DEFAULT : Refreshed 8 property StateModelDefinition took 36 ms. Selective: false
Processed external view change in 12ms (fetch 1 external view stats: 1ms, update routing entry for 1 tables ([meetupRsvp_REALTIME]): 11ms)
Finish handling EXTERNAL_VIEW change for handler: org.apache.pinot.broker.routing.RoutingManager in 12ms
Start processing qps quota change.
No qps quota change: external view for broker resource remains the same.
Finish handling EXTERNAL_VIEW change for handler: org.apache.pinot.broker.queryquota.HelixExternalViewBasedQueryQuotaManager in 3ms
Finish processing EXTERNAL_VIEW change in 15ms
Event QuickStartCluster::TASK::a865fa4c_TASK : 0 properties refreshed from ZK.
Event QuickStartCluster::TASK::a865fa4c_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187475, took 31 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::a865fa4c_DEFAULT : Refreshed 1 property ClusterConstraint took 7 ms. Selective: false
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
START: InstanceMessagesCache.refresh()
Subscribing to path:/QuickStartCluster/EXTERNALVIEW took:18
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event a865fa4c_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187418 took 91 for TASK pipeline
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 2 ms. 
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 92 ms for event a865fa4c_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_TASK
Event QuickStartCluster::DEFAULT::a865fa4c_DEFAULT : 0 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::a865fa4c_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187510, took 2 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event a865fa4c_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187464 took 48 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 48 ms for event a865fa4c_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 1 ms for event a865fa4c_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_TASK
START TaskPersistDataStage.process()
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event a865fa4c_DEFAULT
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 0 ms
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
Event a865fa4c_DEFAULT : Message already exists for Server_172.19.0.2_7000 to transit meetupRsvp_REALTIME.meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 from OFFLINE to ONLINE, isRelay: false
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event a865fa4c_DEFAULT
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_DEFAULT
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
END: Invoking DEFAULT controller pipeline for event MessageChange::a865fa4c_DEFAULT for cluster QuickStartCluster, took 50 ms
Callback time for event: MessageChange took: 1 ms
InQueue time for event: MessageChange took: 82 ms
TotalProcessed time for event: MessageChange took: 50 ms
END TaskPersistDataStage.process() for cluster QuickStartCluster took 1 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 2 ms for event a865fa4c_TASK
START AsyncProcess: TASK::TaskGarbageCollectionStage
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 0 ms
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_TASK
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event a865fa4c_TASK
END: Invoking TASK controller pipeline for event MessageChange::a865fa4c_TASK for cluster QuickStartCluster, took 97 ms
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: CurrentStateChange  f37fa058_TASK
Event f37fa058_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
Event f37fa058_TASK : No ideal state change for QuickStartCluster cluster, TASK pipeline
Event f37fa058_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
Event f37fa058_TASK : No instance config change for QuickStartCluster cluster, TASK pipeline
Event f37fa058_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
The configuration 'auto.commit.enable' was supplied but isn't a known config.
Kafka version : 2.0.0
Kafka commitId : 3402a8361b734732
Created consumer with id org.apache.kafka.clients.consumer.KafkaConsumer@15117927 for topic meetupRSVPEvents
Started kafka stream provider
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:venue_name.sv.unsorted.fwd
Event QuickStartCluster::TASK::f37fa058_TASK : Refreshed 8 property StateModelDefinition took 17 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::f37fa058_TASK : Refreshed 1 property ClusterConstraint took 3 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
Event QuickStartCluster::TASK::f37fa058_TASK : 0 properties refreshed from ZK.
Event QuickStartCluster::TASK::f37fa058_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187540, took 1 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event f37fa058_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187517 took 25 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 25 ms for event f37fa058_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_TASK
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 1 ms for event f37fa058_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_TASK
START TaskPersistDataStage.process()
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_TASK
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
START AsyncProcess: TASK::TaskGarbageCollectionStage
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 0 ms
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_TASK
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event f37fa058_TASK
END: Invoking TASK controller pipeline for event CurrentStateChange::f37fa058_TASK for cluster QuickStartCluster, took 26 ms
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:group_city.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:group_name.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:group_lon.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:mtime.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:rsvp_count.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:event_id.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:group_country.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:group_id.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:event_name.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:location.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:event_time.sv.unsorted.fwd
Allocating 20000000 bytes for: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180:group_lat.sv.unsorted.fwd
Metrics aggregation is disabled.
Starting consumption on realtime consuming segment meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 maxRowCount 5000000 maxEndTime 2020-12-19T02:59:47.435Z
finished scheduling keepIndexing timer check
Initialize RealtimeSegmentDataManager - meetupRsvp_REALTIME_1608325187082_0__0__1608325187180
Added segment: meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 to table: meetupRsvp_REALTIME
Starting to collect rows
Accepted socket connection from /172.19.0.4:49144
Refusing session request for client /172.19.0.4:49144 as it has seen zxid 0x478 our last zxid is 0x168 client must try another server
Closed socket connection for client /172.19.0.4:49144 (no session established for client)
Got user-level KeeperException when processing sessionid:0x10011325aa60008 type:setData cxid:0x144 zxid:0x169 txntype:-1 reqpath:n/a Error Path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008/meetupRsvp_REALTIME Error:KeeperErrorCode = NoNode for /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008/meetupRsvp_REALTIME
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Cluster ID: S7al0OcgSOSdvkSUZFxIDQ
Message dd3a69d3-87ca-40de-b26a-4af6dc322a80 completed.
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 took:8
103 START:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
Delete message dd3a69d3-87ca-40de-b26a-4af6dc322a80 from zk!
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, type: CALLBACK, listener: org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES
Subscribing data change listener to all children for path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008
MBean CLMParticipantReport:Cluster=QuickStartCluster,Duplicate=1,Transition=OFFLINE--ONLINE has been registered.
message finished: dd3a69d3-87ca-40de-b26a-4af6dc322a80, took 409
Message: dd3a69d3-87ca-40de-b26a-4af6dc322a80 (parent: null) handling task for meetupRsvp_REALTIME:meetupRsvp_REALTIME_1608325187082_0__0__1608325187180 completed at: 1608325187784, results: true. FrameworkTime: 5 ms; HandlerTime: 404 ms.
START: GenericClusterController.onStateChange()
END: GenericClusterController.onStateChange()
103 END:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 1ms
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES took:1
226 START:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES listener:org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea type: CALLBACK
No Messages to process
226 END:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES listener:org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea type: CALLBACK Took: 1ms
Controller stopping periodical rebalance timer at period 9223372036854775807
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: CurrentStateChange  cb07d5d0_TASK
Event cb07d5d0_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
Event cb07d5d0_TASK : No ideal state change for QuickStartCluster cluster, TASK pipeline
Event cb07d5d0_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
Event cb07d5d0_TASK : No instance config change for QuickStartCluster cluster, TASK pipeline
Event cb07d5d0_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: CurrentStateChange  cb07d5d0_DEFAULT
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/CURRENTSTATES/10011325aa60008 took:6
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, for listener: org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea, watchChild: false
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, type: CALLBACK, listener: org.apache.helix.messaging.handling.HelixTaskExecutor@50cc93ea
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES
Event cb07d5d0_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Event cb07d5d0_DEFAULT : No ideal state change for QuickStartCluster cluster, DEFAULT pipeline
Event cb07d5d0_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event cb07d5d0_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event cb07d5d0_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES took:2
Got user-level KeeperException when processing sessionid:0x100113247280003 type:setData cxid:0x67 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/kafka/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /kafka/config/topics/__consumer_offsets
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES took:8
103 START:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK
START: GenericClusterController.onMessage() for cluster QuickStartCluster
END: GenericClusterController.onMessage() for cluster QuickStartCluster
103 END:INVOKE /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES listener:org.apache.helix.controller.GenericHelixController@553bc36c type: CALLBACK Took: 1ms
Resubscribe change listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, for listener: org.apache.helix.controller.GenericHelixController@553bc36c, watchChild: false
Subscribing changes listener to path: /QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES, type: CALLBACK, listener: org.apache.helix.controller.GenericHelixController@553bc36c
Subscribing child change listener to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES
Subscribing to path:/QuickStartCluster/INSTANCES/Server_172.19.0.2_7000/MESSAGES took:0
Topic creation Map(__consumer_offsets-22 -> ArrayBuffer(0), __consumer_offsets-30 -> ArrayBuffer(0), __consumer_offsets-8 -> ArrayBuffer(0), __consumer_offsets-21 -> ArrayBuffer(0), __consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-27 -> ArrayBuffer(0), __consumer_offsets-7 -> ArrayBuffer(0), __consumer_offsets-9 -> ArrayBuffer(0), __consumer_offsets-46 -> ArrayBuffer(0), __consumer_offsets-25 -> ArrayBuffer(0), __consumer_offsets-35 -> ArrayBuffer(0), __consumer_offsets-41 -> ArrayBuffer(0), __consumer_offsets-33 -> ArrayBuffer(0), __consumer_offsets-23 -> ArrayBuffer(0), __consumer_offsets-49 -> ArrayBuffer(0), __consumer_offsets-47 -> ArrayBuffer(0), __consumer_offsets-16 -> ArrayBuffer(0), __consumer_offsets-28 -> ArrayBuffer(0), __consumer_offsets-31 -> ArrayBuffer(0), __consumer_offsets-36 -> ArrayBuffer(0), __consumer_offsets-42 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-18 -> ArrayBuffer(0), __consumer_offsets-37 -> ArrayBuffer(0), __consumer_offsets-15 -> ArrayBuffer(0), __consumer_offsets-24 -> ArrayBuffer(0), __consumer_offsets-38 -> ArrayBuffer(0), __consumer_offsets-17 -> ArrayBuffer(0), __consumer_offsets-48 -> ArrayBuffer(0), __consumer_offsets-19 -> ArrayBuffer(0), __consumer_offsets-11 -> ArrayBuffer(0), __consumer_offsets-13 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-43 -> ArrayBuffer(0), __consumer_offsets-6 -> ArrayBuffer(0), __consumer_offsets-14 -> ArrayBuffer(0), __consumer_offsets-20 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-44 -> ArrayBuffer(0), __consumer_offsets-39 -> ArrayBuffer(0), __consumer_offsets-12 -> ArrayBuffer(0), __consumer_offsets-45 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0), __consumer_offsets-5 -> ArrayBuffer(0), __consumer_offsets-26 -> ArrayBuffer(0), __consumer_offsets-29 -> ArrayBuffer(0), __consumer_offsets-34 -> ArrayBuffer(0), __consumer_offsets-10 -> ArrayBuffer(0), __consumer_offsets-32 -> ArrayBuffer(0), __consumer_offsets-40 -> ArrayBuffer(0))
[KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
[Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-22 -> Vector(0), __consumer_offsets-30 -> Vector(0), __consumer_offsets-8 -> Vector(0), __consumer_offsets-21 -> Vector(0), __consumer_offsets-4 -> Vector(0), __consumer_offsets-27 -> Vector(0), __consumer_offsets-7 -> Vector(0), __consumer_offsets-9 -> Vector(0), __consumer_offsets-46 -> Vector(0), __consumer_offsets-25 -> Vector(0), __consumer_offsets-35 -> Vector(0), __consumer_offsets-41 -> Vector(0), __consumer_offsets-33 -> Vector(0), __consumer_offsets-23 -> Vector(0), __consumer_offsets-49 -> Vector(0), __consumer_offsets-47 -> Vector(0), __consumer_offsets-16 -> Vector(0), __consumer_offsets-28 -> Vector(0), __consumer_offsets-31 -> Vector(0), __consumer_offsets-36 -> Vector(0), __consumer_offsets-42 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-18 -> Vector(0), __consumer_offsets-37 -> Vector(0), __consumer_offsets-15 -> Vector(0), __consumer_offsets-24 -> Vector(0), __consumer_offsets-38 -> Vector(0), __consumer_offsets-17 -> Vector(0), __consumer_offsets-48 -> Vector(0), __consumer_offsets-19 -> Vector(0), __consumer_offsets-11 -> Vector(0), __consumer_offsets-13 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-43 -> Vector(0), __consumer_offsets-6 -> Vector(0), __consumer_offsets-14 -> Vector(0), __consumer_offsets-20 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-44 -> Vector(0), __consumer_offsets-39 -> Vector(0), __consumer_offsets-12 -> Vector(0), __consumer_offsets-45 -> Vector(0), __consumer_offsets-1 -> Vector(0), __consumer_offsets-5 -> Vector(0), __consumer_offsets-26 -> Vector(0), __consumer_offsets-29 -> Vector(0), __consumer_offsets-34 -> Vector(0), __consumer_offsets-10 -> Vector(0), __consumer_offsets-32 -> Vector(0), __consumer_offsets-40 -> Vector(0))]
[Controller id=0] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
Event QuickStartCluster::TASK::cb07d5d0_TASK : Refreshed 8 property StateModelDefinition took 22 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::cb07d5d0_TASK : Refreshed 1 property ClusterConstraint took 5 ms. Selective: false
START: InstanceMessagesCache.refresh()
Event QuickStartCluster::DEFAULT::cb07d5d0_DEFAULT : Refreshed 8 property StateModelDefinition took 27 ms. Selective: false
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::cb07d5d0_DEFAULT : Refreshed 1 property ClusterConstraint took 3 ms. Selective: false
Event QuickStartCluster::TASK::cb07d5d0_TASK : 1 properties refreshed from ZK.
Event QuickStartCluster::TASK::cb07d5d0_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187818, took 5 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
START: InstanceMessagesCache.refresh()
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event cb07d5d0_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187789 took 35 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 36 ms for event cb07d5d0_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_TASK
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 2 ms. 
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_TASK
START TaskPersistDataStage.process()
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_TASK
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
START AsyncProcess: TASK::TaskGarbageCollectionStage
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 0 ms
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_TASK
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_TASK
END: Invoking TASK controller pipeline for event CurrentStateChange::cb07d5d0_TASK for cluster QuickStartCluster, took 39 ms
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster TASK event: MessageChange  ab212327_TASK
Event ab212327_TASK : No ClusterConfig change for cluster QuickStartCluster, pipeline TASK
Event ab212327_TASK : No ideal state change for QuickStartCluster cluster, TASK pipeline
Event ab212327_TASK : No live instance change for QuickStartCluster cluster, TASK pipeline
Event ab212327_TASK : No instance config change for QuickStartCluster cluster, TASK pipeline
Event ab212327_TASK : No resource config change for QuickStartCluster cluster, TASK pipeline
Event QuickStartCluster::DEFAULT::cb07d5d0_DEFAULT : 1 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::cb07d5d0_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187826, took 12 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event cb07d5d0_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187789 took 49 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 49 ms for event cb07d5d0_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event cb07d5d0_DEFAULT
Submitted asynchronous DEFAULT::ExternalViewComputeStage task to worker
START AsyncProcess: DEFAULT::ExternalViewComputeStage
END ExternalViewComputeStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 0 ms
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
START AsyncProcess: DEFAULT::PersistAssignmentStage
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event cb07d5d0_DEFAULT
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END: Invoking DEFAULT controller pipeline for event CurrentStateChange::cb07d5d0_DEFAULT for cluster QuickStartCluster, took 55 ms
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
Callback time for event: CurrentStateChange took: 9 ms
InQueue time for event: CurrentStateChange took: 5 ms
TotalProcessed time for event: CurrentStateChange took: 55 ms
195 START:INVOKE /QuickStartCluster/EXTERNALVIEW listener:org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93 type: CALLBACK
Enqueue EXTERNAL_VIEW change
Resubscribe change listener to path: /QuickStartCluster/EXTERNALVIEW, for listener: org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93, watchChild: true
Subscribing changes listener to path: /QuickStartCluster/EXTERNALVIEW, type: CALLBACK, listener: org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93
Subscribing child change listener to path:/QuickStartCluster/EXTERNALVIEW
195 END:INVOKE /QuickStartCluster/EXTERNALVIEW listener:org.apache.pinot.broker.broker.helix.ClusterChangeMediator@34c30b93 type: CALLBACK Took: 0ms
Start processing EXTERNAL_VIEW change
Processing external view change
Subscribing data change listener to all children for path:/QuickStartCluster/EXTERNALVIEW
Controller stopping periodical rebalance timer at period 9223372036854775807
START: Invoking QuickStartCluster controller pipeline for cluster DEFAULT event: MessageChange  ab212327_DEFAULT
Event ab212327_DEFAULT : No ClusterConfig change for cluster QuickStartCluster, pipeline DEFAULT
Event ab212327_DEFAULT : No ideal state change for QuickStartCluster cluster, DEFAULT pipeline
Event ab212327_DEFAULT : No live instance change for QuickStartCluster cluster, DEFAULT pipeline
Event ab212327_DEFAULT : No instance config change for QuickStartCluster cluster, DEFAULT pipeline
Event ab212327_DEFAULT : No resource config change for QuickStartCluster cluster, DEFAULT pipeline
END AsyncProcess: DEFAULT::ExternalViewComputeStage, took 11 ms
Processed external view change in 10ms (fetch 1 external view stats: 1ms, update routing entry for 1 tables ([meetupRsvp_REALTIME]): 9ms)
Finish handling EXTERNAL_VIEW change for handler: org.apache.pinot.broker.routing.RoutingManager in 11ms
Subscribing to path:/QuickStartCluster/EXTERNALVIEW took:15
Start processing qps quota change.
No qps quota change: external view for broker resource remains the same.
Finish handling EXTERNAL_VIEW change for handler: org.apache.pinot.broker.queryquota.HelixExternalViewBasedQueryQuotaManager in 4ms
Finish processing EXTERNAL_VIEW change in 15ms
Event QuickStartCluster::TASK::ab212327_TASK : Refreshed 8 property StateModelDefinition took 31 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::TASK::ab212327_TASK : Refreshed 1 property ClusterConstraint took 3 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
Event QuickStartCluster::DEFAULT::ab212327_DEFAULT : Refreshed 8 property StateModelDefinition took 21 ms. Selective: false
overwrite existing constraint-value. old-value: null, new-value: 100000
Event QuickStartCluster::DEFAULT::ab212327_DEFAULT : Refreshed 1 property ClusterConstraint took 3 ms. Selective: false
START: InstanceMessagesCache.refresh()
END: InstanceMessagesCache.refresh(), 0 of Messages read from ZooKeeper. took 1 ms. 
Event QuickStartCluster::DEFAULT::ab212327_DEFAULT : 0 properties refreshed from ZK.
Event QuickStartCluster::DEFAULT::ab212327_DEFAULT : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187877, took 4 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
Event ab212327_DEFAULT : END: ResourceControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187851 took 30 for DEFAULT pipeline
END ReadClusterDataStage for DEFAULT pipeline for cluster QuickStartCluster. took: 30 ms for event ab212327_DEFAULT
END ResourceComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
END ResourceValidationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
END CurrentStateComputationStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
END TopStateHandoffReportStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
Computing IdealState for leadControllerResource
found the following participants with tag controller for leadControllerResource: [Controller_172.19.0.2_9000]
Event QuickStartCluster::TASK::ab212327_TASK : 0 properties refreshed from ZK.
Event QuickStartCluster::TASK::ab212327_TASK : END: CurrentStateCache.refresh() for cluster QuickStartCluster, started at : 1608325187871, took 14 ms
END: updateRelayMessages(), 0 of valid relay messages in cache, took 0 ms. 
AssignableInstanceManager built AssignableInstances from scratch based on contexts in TaskDataCache due to Controller switch or ClusterConfig change.
Current quota capacity: {"Broker_172.19.0.2_8000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Controller_172.19.0.2_9000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}},"Server_172.19.0.2_7000":{"TASK_EXEC_THREAD":{"DEFAULT":"0/40"}}}
Event ab212327_TASK : END: WorkflowControllerDataProvider.refresh() for cluster QuickStartCluster, started at 1608325187836 took 50 for TASK pipeline
END ReadClusterDataStage for TASK pipeline for cluster QuickStartCluster. took: 50 ms for event ab212327_TASK
END ResourceComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_TASK
END ResourceValidationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_TASK
END CurrentStateComputationStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_TASK
END TaskSchedulingStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_TASK
START TaskPersistDataStage.process()
END TaskPersistDataStage.process() for cluster QuickStartCluster took 0 ms
END TaskPersistDataStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_TASK
Submitted asynchronous TASK::TaskGarbageCollectionStage task to worker
END TaskGarbageCollectionStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_TASK
END TaskMessageGenerationPhase for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_TASK
END TaskMessageDispatchStage for TASK pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_TASK
END: Invoking TASK controller pipeline for event MessageChange::ab212327_TASK for cluster QuickStartCluster, took 52 ms
END BestPossibleStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 3 ms for event ab212327_DEFAULT
START AsyncProcess: TASK::TaskGarbageCollectionStage
END AsyncProcess: TASK::TaskGarbageCollectionStage, took 1 ms
No throttle config is set!
END IntermediateStateCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
START AsyncProcess: DEFAULT::MaintenanceRecoveryStage
END AsyncProcess: DEFAULT::MaintenanceRecoveryStage, took 0 ms
Submitted asynchronous DEFAULT::MaintenanceRecoveryStage task to worker
END MaintenanceRecoveryStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event ab212327_DEFAULT
END ResourceMessageGenerationPhase for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
END MessageSelectionStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
END MessageThrottleStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
END ResourceMessageDispatchStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
Submitted asynchronous DEFAULT::PersistAssignmentStage task to worker
END PersistAssignmentStage for DEFAULT pipeline for cluster QuickStartCluster. took: 1 ms for event ab212327_DEFAULT
Submitted asynchronous DEFAULT::TargetExteralViewCalcStage task to worker
END TargetExteralViewCalcStage for DEFAULT pipeline for cluster QuickStartCluster. took: 0 ms for event ab212327_DEFAULT
END: Invoking DEFAULT controller pipeline for event MessageChange::ab212327_DEFAULT for cluster QuickStartCluster, took 39 ms
Callback time for event: MessageChange took: 8 ms
InQueue time for event: MessageChange took: 54 ms
TotalProcessed time for event: MessageChange took: 39 ms
START AsyncProcess: DEFAULT::PersistAssignmentStage
END AsyncProcess: DEFAULT::PersistAssignmentStage, took 0 ms
START AsyncProcess: DEFAULT::TargetExteralViewCalcStage
END AsyncProcess: DEFAULT::TargetExteralViewCalcStage, took 0 ms
[ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
[Log partition=__consumer_offsets-0, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-0, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-0 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
[Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-29, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-29, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-29 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29
Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
[Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-48, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-48, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-48 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48
Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
[Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-10, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-10, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-10 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10
Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
[Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-45, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-45, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-45 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45
Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
[Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-26, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-26, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-26 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26
Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
[Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-7, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-7, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-7 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7
Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
[Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-42, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-42, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-42 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42
Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
[Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-4, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-4, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-4 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
[Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-23, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-23, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-23 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23
Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
[Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-1, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-1, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-1 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
[Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-20, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-20, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-20 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20
Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
[Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-39, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-39, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-39 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39
Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
[Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-17, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-17, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-17 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17
Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
[Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-36, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-36, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-36 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36
Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
[Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-14, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-14, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-14 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14
Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
[Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-33, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-33, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-33 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33
Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
[Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-49, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-49, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-49 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49
Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
[Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-11, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-11, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-11 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11
Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
[Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-30, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-30, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-30 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30
Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
[Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-46, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-46, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-46 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46
Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
[Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-27, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-27, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-27 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27
Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
[Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-8, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-8, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-8 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8
Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
[Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-24, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-24, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-24 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24
Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
[Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-43, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-43, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-43 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43
Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
[Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-5, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-5, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-5 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5
Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
[Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-21, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-21, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-21 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21
Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
[Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-2, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-2, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-2 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
[Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-40, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-40, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-40 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40
Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
[Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-37, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-37, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-37 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37
Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
[Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-18, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-18, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-18 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18
Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
[Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-34, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-34, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
Created log for partition __consumer_offsets-34 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34
Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
[Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-15, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-15, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-15 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15
Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
[Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-12, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-12, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-12 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12
Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
[Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-31, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-31, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-31 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31
Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
[Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-9, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-9, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-9 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9
Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
[Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-47, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-47, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-47 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47
Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
[Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-19, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-19, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-19 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19
Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
[Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-28, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-28, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-28 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28
Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
[Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-38, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-38, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-38 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38
Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
[Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-35, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-35, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-35 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35
Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
[Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-44, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-44, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-44 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44
Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
[Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-6, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-6, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-6 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6
Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
[Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-25, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-25, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-25 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25
Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
[Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-16, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-16, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-16 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16
Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
[Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-22, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-22, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms
Created log for partition __consumer_offsets-22 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22
Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
[Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-41, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-41, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-41 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41
Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
[Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-32, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-32, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-32 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32
Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
[Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-3, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-3, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
Created log for partition __consumer_offsets-3 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
[Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[Log partition=__consumer_offsets-13, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Loading producer state till offset 0 with message format version 2
[Log partition=__consumer_offsets-13, dir=/tmp/kafka-0x1.f4a1ac11fcd7ap-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
Created log for partition __consumer_offsets-13 in /tmp/kafka-0x1.f4a1ac11fcd7ap-1 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13
Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
[Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 6 milliseconds.
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds.
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45
[GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
[GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Discovered group coordinator localhost:19092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Revoking previously assigned partitions []
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] (Re-)joining group
[GroupCoordinator 0]: Preparing to rebalance group meetupRsvp_REALTIME_1608325187082_0 with old generation 0 (__consumer_offsets-22)
Accepted socket connection from /172.19.0.4:49152
Refusing session request for client /172.19.0.4:49152 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49152 (no session established for client)
Accepted socket connection from /172.19.0.4:49154
Refusing session request for client /172.19.0.4:49154 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49154 (no session established for client)
[GroupCoordinator 0]: Stabilized group meetupRsvp_REALTIME_1608325187082_0 generation 1 (__consumer_offsets-22)
[GroupCoordinator 0]: Assignment received from leader for group meetupRsvp_REALTIME_1608325187082_0 for generation 1
Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: __consumer_offsets-22. Cache now contains 0 entries.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Successfully joined group with generation 1
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Setting newly assigned partitions [meetupRSVPEvents-2, meetupRSVPEvents-3, meetupRSVPEvents-0, meetupRSVPEvents-1, meetupRSVPEvents-6, meetupRSVPEvents-7, meetupRSVPEvents-4, meetupRSVPEvents-5, meetupRSVPEvents-8, meetupRSVPEvents-9]
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-2 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-3 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-0 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-1 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-6 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-7 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-4 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-5 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-8 to offset 2.
[Consumer clientId=consumer-1, groupId=meetupRsvp_REALTIME_1608325187082_0] Resetting offset for partition meetupRSVPEvents-9 to offset 2.
Consumed 1 events from kafka stream meetupRSVPEvents
Accepted socket connection from /172.19.0.4:49156
Refusing session request for client /172.19.0.4:49156 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49156 (no session established for client)
[33m***** Realtime quickstart setup complete *****[0m
[33mTotal number of documents in the table[0m
[36mQuery : select count(*) from meetupRsvp limit 1[0m
Executing command: PostQuery -brokerHost 172.19.0.2 -brokerPort 8000 -queryType sql -query select count(*) from meetupRsvp limit 1
Channel for server: 172.19.0.2_R is now active
Processed requestId=1,table=meetupRsvp_REALTIME,segments(queried/processed/matched/consuming)=1/1/1/1,schedulerWaitMs=7,reqDeserMs=6,totalExecMs=14,resSerMs=0,totalTimeMs=27,minConsumingFreshnessMs=1608325191492,broker=Broker_172.19.0.2_8000,numDocsScanned=2,scanInFilter=0,scanPostFilter=0,sched=fcfs
requestId=1,table=meetupRsvp_REALTIME,timeMs=390,docs=2/2,entries=0/0,segments(queried/processed/matched/consuming/unavailable):1/1/1/1/0,consumingFreshnessTimeMs=1608325191492,servers=1/1,groupLimitReached=false,brokerReduceTimeMs=7,exceptions=0,serverStats=(Server=SubmitDelayMs,ResponseDelayMs,ResponseSize,DeserializationTimeMs);172.19.0.2_R=42,47,452,1,query=select count(*) from meetupRsvp limit 1
[33mcount(*)		
2		
[0m
[32m***************************************************[0m
[33mTop 10 cities with the most rsvp[0m
[36mQuery : select group_city, sum(rsvp_count) from meetupRsvp group by group_city order by sum(rsvp_count) desc limit 10[0m
Executing command: PostQuery -brokerHost 172.19.0.2 -brokerPort 8000 -queryType sql -query select group_city, sum(rsvp_count) from meetupRsvp group by group_city order by sum(rsvp_count) desc limit 10
Processed requestId=2,table=meetupRsvp_REALTIME,segments(queried/processed/matched/consuming)=1/1/1/1,schedulerWaitMs=0,reqDeserMs=2,totalExecMs=25,resSerMs=0,totalTimeMs=27,minConsumingFreshnessMs=1608325191492,broker=Broker_172.19.0.2_8000,numDocsScanned=2,scanInFilter=0,scanPostFilter=4,sched=fcfs
requestId=2,table=meetupRsvp_REALTIME,timeMs=50,docs=2/2,entries=0/4,segments(queried/processed/matched/consuming/unavailable):1/1/1/1/0,consumingFreshnessTimeMs=1608325191492,servers=1/1,groupLimitReached=false,brokerReduceTimeMs=4,exceptions=0,serverStats=(Server=SubmitDelayMs,ResponseDelayMs,ResponseSize,DeserializationTimeMs);172.19.0.2_R=2,28,547,0,query=select group_city, sum(rsvp_count) from meetupRsvp group by group_city order by sum(rsvp_count) desc limit 10
[33mgroup_city		sum(rsvp_count)		
Brisbane		1.0		
London		1.0		
[0m
[32m***************************************************[0m
[33mShow 10 most recent rsvps[0m
[36mQuery : select * from meetupRsvp order by mtime limit 10[0m
Executing command: PostQuery -brokerHost 172.19.0.2 -brokerPort 8000 -queryType sql -query select * from meetupRsvp order by mtime limit 10
Processed requestId=3,table=meetupRsvp_REALTIME,segments(queried/processed/matched/consuming)=1/1/1/1,schedulerWaitMs=3,reqDeserMs=0,totalExecMs=39,resSerMs=0,totalTimeMs=42,minConsumingFreshnessMs=1608325191492,broker=Broker_172.19.0.2_8000,numDocsScanned=2,scanInFilter=0,scanPostFilter=28,sched=fcfs
requestId=3,table=meetupRsvp_REALTIME,timeMs=54,docs=2/2,entries=0/28,segments(queried/processed/matched/consuming/unavailable):1/1/1/1/0,consumingFreshnessTimeMs=1608325191492,servers=1/1,groupLimitReached=false,brokerReduceTimeMs=3,exceptions=0,serverStats=(Server=SubmitDelayMs,ResponseDelayMs,ResponseSize,DeserializationTimeMs);172.19.0.2_R=1,48,1399,0,query=select * from meetupRsvp order by mtime limit 10
[33mevent_id		event_name		event_time		group_city		group_country		group_id		group_lat		group_lon		group_name		location		mtime		rsvp_count		venue_name		
275255176		Bribie Island Eco tour  + Bonus Night tour 		1609279200000		Brisbane		au		32655295		-27.46		153.02		Brisbane multicultural,  friendship group.		00406320a3d70a3d71c03b75c28f5c28f6		1608325191336		1		Online event		
275170349		Dealing with Grief - (Serena - Chatting Uncomfortably) 		1610650800000		London		gb		34202120		51.52		-0.1		South Asian Women’s Chai and Chat		00bfb999999999999a4049c28f5c28f5c3		1608325191444		1		null		
[0m
[32m***************************************************[0m
[33mShow top 10 rsvp'ed events[0m
[36mQuery : select event_name, sum(rsvp_count) from meetupRsvp group by event_name order by sum(rsvp_count) desc limit 10[0m
Executing command: PostQuery -brokerHost 172.19.0.2 -brokerPort 8000 -queryType sql -query select event_name, sum(rsvp_count) from meetupRsvp group by event_name order by sum(rsvp_count) desc limit 10
Processed requestId=4,table=meetupRsvp_REALTIME,segments(queried/processed/matched/consuming)=1/1/1/1,schedulerWaitMs=0,reqDeserMs=1,totalExecMs=3,resSerMs=0,totalTimeMs=4,minConsumingFreshnessMs=1608325191492,broker=Broker_172.19.0.2_8000,numDocsScanned=2,scanInFilter=0,scanPostFilter=4,sched=fcfs
requestId=4,table=meetupRsvp_REALTIME,timeMs=10,docs=2/2,entries=0/4,segments(queried/processed/matched/consuming/unavailable):1/1/1/1/0,consumingFreshnessTimeMs=1608325191492,servers=1/1,groupLimitReached=false,brokerReduceTimeMs=0,exceptions=0,serverStats=(Server=SubmitDelayMs,ResponseDelayMs,ResponseSize,DeserializationTimeMs);172.19.0.2_R=1,6,630,0,query=select event_name, sum(rsvp_count) from meetupRsvp group by event_name order by sum(rsvp_count) desc limit 10
[33mevent_name		sum(rsvp_count)		
Bribie Island Eco tour  + Bonus Night tour 		1.0		
Dealing with Grief - (Serena - Chatting Uncomfortably) 		1.0		
[0m
[32m***************************************************[0m
[33mTotal number of documents in the table[0m
[36mQuery : select count(*) from meetupRsvp limit 1[0m
Executing command: PostQuery -brokerHost 172.19.0.2 -brokerPort 8000 -queryType sql -query select count(*) from meetupRsvp limit 1
Processed requestId=5,table=meetupRsvp_REALTIME,segments(queried/processed/matched/consuming)=1/1/1/1,schedulerWaitMs=0,reqDeserMs=1,totalExecMs=0,resSerMs=0,totalTimeMs=1,minConsumingFreshnessMs=1608325191492,broker=Broker_172.19.0.2_8000,numDocsScanned=2,scanInFilter=0,scanPostFilter=0,sched=fcfs
requestId=5,table=meetupRsvp_REALTIME,timeMs=4,docs=2/2,entries=0/0,segments(queried/processed/matched/consuming/unavailable):1/1/1/1/0,consumingFreshnessTimeMs=1608325191492,servers=1/1,groupLimitReached=false,brokerReduceTimeMs=0,exceptions=0,serverStats=(Server=SubmitDelayMs,ResponseDelayMs,ResponseSize,DeserializationTimeMs);172.19.0.2_R=0,3,451,0,query=select count(*) from meetupRsvp limit 1
[33mcount(*)		
2		
[0m
[32m***************************************************[0m
[32mYou can always go to http://localhost:9000 to play around in the query console[0m
Accepted socket connection from /172.19.0.4:49162
Refusing session request for client /172.19.0.4:49162 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49162 (no session established for client)
Accepted socket connection from /172.19.0.4:49164
Refusing session request for client /172.19.0.4:49164 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49164 (no session established for client)
Accepted socket connection from /172.19.0.4:49166
Refusing session request for client /172.19.0.4:49166 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49166 (no session established for client)
Accepted socket connection from /172.19.0.4:49168
Refusing session request for client /172.19.0.4:49168 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49168 (no session established for client)
Accepted socket connection from /172.19.0.4:49170
Refusing session request for client /172.19.0.4:49170 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49170 (no session established for client)
Accepted socket connection from /172.19.0.4:49172
Refusing session request for client /172.19.0.4:49172 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49172 (no session established for client)
Accepted socket connection from /172.19.0.4:49174
Refusing session request for client /172.19.0.4:49174 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49174 (no session established for client)
Accepted socket connection from /172.19.0.4:49176
Refusing session request for client /172.19.0.4:49176 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49176 (no session established for client)
Accepted socket connection from /172.19.0.4:49178
Refusing session request for client /172.19.0.4:49178 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49178 (no session established for client)
Accepted socket connection from /172.19.0.4:49180
Refusing session request for client /172.19.0.4:49180 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49180 (no session established for client)
Accepted socket connection from /172.19.0.4:49182
Refusing session request for client /172.19.0.4:49182 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49182 (no session established for client)
Accepted socket connection from /172.19.0.4:49184
Refusing session request for client /172.19.0.4:49184 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49184 (no session established for client)
Accepted socket connection from /172.19.0.4:49186
Refusing session request for client /172.19.0.4:49186 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49186 (no session established for client)
Accepted socket connection from /172.19.0.4:49188
Refusing session request for client /172.19.0.4:49188 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49188 (no session established for client)
Accepted socket connection from /172.19.0.4:49190
Refusing session request for client /172.19.0.4:49190 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49190 (no session established for client)
Accepted socket connection from /172.19.0.4:49192
Refusing session request for client /172.19.0.4:49192 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49192 (no session established for client)
Accepted socket connection from /172.19.0.4:49194
Refusing session request for client /172.19.0.4:49194 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49194 (no session established for client)
Accepted socket connection from /172.19.0.4:49196
Refusing session request for client /172.19.0.4:49196 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49196 (no session established for client)
Accepted socket connection from /172.19.0.4:49198
Refusing session request for client /172.19.0.4:49198 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49198 (no session established for client)
Getting Helix leader: 172.19.0.2_9000, Helix version: 0.9.8, mtime: 1608325163124
Accepted socket connection from /172.19.0.4:49200
Refusing session request for client /172.19.0.4:49200 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49200 (no session established for client)
Accepted socket connection from /172.19.0.4:49202
Refusing session request for client /172.19.0.4:49202 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49202 (no session established for client)
Accepted socket connection from /172.19.0.4:49204
Refusing session request for client /172.19.0.4:49204 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49204 (no session established for client)
Accepted socket connection from /172.19.0.4:49206
Refusing session request for client /172.19.0.4:49206 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49206 (no session established for client)
Accepted socket connection from /172.19.0.4:49208
Refusing session request for client /172.19.0.4:49208 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49208 (no session established for client)
Accepted socket connection from /172.19.0.4:49210
Refusing session request for client /172.19.0.4:49210 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49210 (no session established for client)
Accepted socket connection from /172.19.0.4:49212
Refusing session request for client /172.19.0.4:49212 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49212 (no session established for client)
Accepted socket connection from /172.19.0.4:49214
Refusing session request for client /172.19.0.4:49214 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49214 (no session established for client)
Accepted socket connection from /172.19.0.4:49216
Refusing session request for client /172.19.0.4:49216 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49216 (no session established for client)
Accepted socket connection from /172.19.0.4:49218
Refusing session request for client /172.19.0.4:49218 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49218 (no session established for client)
Accepted socket connection from /172.19.0.4:49220
Refusing session request for client /172.19.0.4:49220 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49220 (no session established for client)
Accepted socket connection from /172.19.0.4:49222
Refusing session request for client /172.19.0.4:49222 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49222 (no session established for client)
Accepted socket connection from /172.19.0.4:49224
Refusing session request for client /172.19.0.4:49224 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49224 (no session established for client)
Accepted socket connection from /172.19.0.4:49226
Refusing session request for client /172.19.0.4:49226 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49226 (no session established for client)
Accepted socket connection from /172.19.0.4:49228
Refusing session request for client /172.19.0.4:49228 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49228 (no session established for client)
Accepted socket connection from /172.19.0.4:49230
Refusing session request for client /172.19.0.4:49230 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49230 (no session established for client)
Accepted socket connection from /172.19.0.4:49232
Refusing session request for client /172.19.0.4:49232 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49232 (no session established for client)
Consumed 49 events from kafka stream meetupRSVPEvents (rate:0.8074616/s)
Accepted socket connection from /172.19.0.4:49234
Refusing session request for client /172.19.0.4:49234 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49234 (no session established for client)
Accepted socket connection from /172.19.0.4:49236
Refusing session request for client /172.19.0.4:49236 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49236 (no session established for client)
Accepted socket connection from /172.19.0.4:49238
Refusing session request for client /172.19.0.4:49238 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49238 (no session established for client)
Accepted socket connection from /172.19.0.4:49240
Refusing session request for client /172.19.0.4:49240 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49240 (no session established for client)
Accepted socket connection from /172.19.0.4:49242
Refusing session request for client /172.19.0.4:49242 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49242 (no session established for client)
Accepted socket connection from /172.19.0.4:49244
Refusing session request for client /172.19.0.4:49244 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49244 (no session established for client)
Accepted socket connection from /172.19.0.4:49246
Refusing session request for client /172.19.0.4:49246 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49246 (no session established for client)
Accepted socket connection from /172.19.0.4:49248
Refusing session request for client /172.19.0.4:49248 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49248 (no session established for client)
Accepted socket connection from /172.19.0.4:49250
Refusing session request for client /172.19.0.4:49250 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49250 (no session established for client)
Accepted socket connection from /172.19.0.4:49252
Refusing session request for client /172.19.0.4:49252 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49252 (no session established for client)
Accepted socket connection from /172.19.0.4:49254
Refusing session request for client /172.19.0.4:49254 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49254 (no session established for client)
Accepted socket connection from /172.19.0.4:49256
Refusing session request for client /172.19.0.4:49256 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49256 (no session established for client)
Accepted socket connection from /172.19.0.4:49258
Refusing session request for client /172.19.0.4:49258 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49258 (no session established for client)
Accepted socket connection from /172.19.0.4:49260
Refusing session request for client /172.19.0.4:49260 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49260 (no session established for client)
Accepted socket connection from /172.19.0.4:49262
Refusing session request for client /172.19.0.4:49262 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49262 (no session established for client)
Accepted socket connection from /172.19.0.4:49264
Refusing session request for client /172.19.0.4:49264 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49264 (no session established for client)
Accepted socket connection from /172.19.0.4:49266
Refusing session request for client /172.19.0.4:49266 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49266 (no session established for client)
Accepted socket connection from /172.19.0.4:49268
Refusing session request for client /172.19.0.4:49268 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49268 (no session established for client)
Accepted socket connection from /172.19.0.4:49270
Refusing session request for client /172.19.0.4:49270 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49270 (no session established for client)
Accepted socket connection from /172.19.0.4:49272
Refusing session request for client /172.19.0.4:49272 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49272 (no session established for client)
Getting Helix leader: 172.19.0.2_9000, Helix version: 0.9.8, mtime: 1608325163124
Accepted socket connection from /172.19.0.4:49274
Refusing session request for client /172.19.0.4:49274 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49274 (no session established for client)
Accepted socket connection from /172.19.0.4:49276
Refusing session request for client /172.19.0.4:49276 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49276 (no session established for client)
Accepted socket connection from /172.19.0.4:49278
Refusing session request for client /172.19.0.4:49278 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49278 (no session established for client)
Accepted socket connection from /172.19.0.4:49280
Refusing session request for client /172.19.0.4:49280 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49280 (no session established for client)
Accepted socket connection from /172.19.0.4:49282
Refusing session request for client /172.19.0.4:49282 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49282 (no session established for client)
Accepted socket connection from /172.19.0.4:49284
Refusing session request for client /172.19.0.4:49284 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49284 (no session established for client)
Accepted socket connection from /172.19.0.4:49286
Refusing session request for client /172.19.0.4:49286 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49286 (no session established for client)
Accepted socket connection from /172.19.0.4:49288
Refusing session request for client /172.19.0.4:49288 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49288 (no session established for client)
Accepted socket connection from /172.19.0.4:49290
Refusing session request for client /172.19.0.4:49290 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49290 (no session established for client)
Accepted socket connection from /172.19.0.4:49292
Refusing session request for client /172.19.0.4:49292 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49292 (no session established for client)
Accepted socket connection from /172.19.0.4:49294
Refusing session request for client /172.19.0.4:49294 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49294 (no session established for client)
Accepted socket connection from /172.19.0.4:49296
Refusing session request for client /172.19.0.4:49296 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49296 (no session established for client)
Accepted socket connection from /172.19.0.4:49298
Refusing session request for client /172.19.0.4:49298 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49298 (no session established for client)
Accepted socket connection from /172.19.0.4:49300
Refusing session request for client /172.19.0.4:49300 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49300 (no session established for client)
Starting SegmentStatusChecker with running frequency of 300 seconds.
Start running task: SegmentStatusChecker
Processing 1 tables in task: SegmentStatusChecker
Finish processing 1/1 tables in task: SegmentStatusChecker
Finish running task: SegmentStatusChecker in 7ms
Accepted socket connection from /172.19.0.4:49302
Refusing session request for client /172.19.0.4:49302 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49302 (no session established for client)
Accepted socket connection from /172.19.0.4:49304
Refusing session request for client /172.19.0.4:49304 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49304 (no session established for client)
Accepted socket connection from /172.19.0.4:49306
Refusing session request for client /172.19.0.4:49306 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49306 (no session established for client)
Accepted socket connection from /172.19.0.4:49308
Refusing session request for client /172.19.0.4:49308 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49308 (no session established for client)
Consumed 41 events from kafka stream meetupRSVPEvents (rate:0.679697/s)
Accepted socket connection from /172.19.0.4:49310
Refusing session request for client /172.19.0.4:49310 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49310 (no session established for client)
Accepted socket connection from /172.19.0.4:49312
Refusing session request for client /172.19.0.4:49312 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49312 (no session established for client)
Starting SegmentRelocator with running frequency of 3600 seconds.
Start running task: SegmentRelocator
Processing 1 tables in task: SegmentRelocator
Finish processing 1/1 tables in task: SegmentRelocator
Finish running task: SegmentRelocator in 4ms
Accepted socket connection from /172.19.0.4:49314
Refusing session request for client /172.19.0.4:49314 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49314 (no session established for client)
Accepted socket connection from /172.19.0.4:49316
Refusing session request for client /172.19.0.4:49316 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49316 (no session established for client)
Accepted socket connection from /172.19.0.4:49318
Refusing session request for client /172.19.0.4:49318 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49318 (no session established for client)
Accepted socket connection from /172.19.0.4:49320
Refusing session request for client /172.19.0.4:49320 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49320 (no session established for client)
Accepted socket connection from /172.19.0.4:49322
Refusing session request for client /172.19.0.4:49322 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49322 (no session established for client)
Accepted socket connection from /172.19.0.4:49324
Refusing session request for client /172.19.0.4:49324 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49324 (no session established for client)
Accepted socket connection from /172.19.0.4:49326
Refusing session request for client /172.19.0.4:49326 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49326 (no session established for client)
Accepted socket connection from /172.19.0.4:49328
Refusing session request for client /172.19.0.4:49328 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49328 (no session established for client)
Accepted socket connection from /172.19.0.4:49330
Refusing session request for client /172.19.0.4:49330 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49330 (no session established for client)
Accepted socket connection from /172.19.0.4:49332
Refusing session request for client /172.19.0.4:49332 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49332 (no session established for client)
Accepted socket connection from /172.19.0.4:49334
Refusing session request for client /172.19.0.4:49334 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49334 (no session established for client)
Accepted socket connection from /172.19.0.4:49336
Refusing session request for client /172.19.0.4:49336 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49336 (no session established for client)
Accepted socket connection from /172.19.0.4:49338
Refusing session request for client /172.19.0.4:49338 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49338 (no session established for client)
Accepted socket connection from /172.19.0.4:49340
Refusing session request for client /172.19.0.4:49340 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49340 (no session established for client)
Starting RetentionManager with running frequency of 21600 seconds.
Start running task: RetentionManager
Processing 1 tables in task: RetentionManager
Start managing retention for table: meetupRsvp_REALTIME
Segment lineage metadata clean-up is successfully processed for table: meetupRsvp_REALTIME
Removing aged (more than 7 days) deleted segments for all tables
Deleted segment directory file:/tmp/1608325154994/meetupRsvp/rawdata/PinotControllerDir0/Deleted_Segments does not exist or it is not directory.
Finish processing 1/1 tables in task: RetentionManager
Finish running task: RetentionManager in 9ms
Accepted socket connection from /172.19.0.4:49342
Refusing session request for client /172.19.0.4:49342 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49342 (no session established for client)
Accepted socket connection from /172.19.0.4:49344
Refusing session request for client /172.19.0.4:49344 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49344 (no session established for client)
Accepted socket connection from /172.19.0.4:49346
Refusing session request for client /172.19.0.4:49346 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49346 (no session established for client)
Accepted socket connection from /172.19.0.4:49348
Refusing session request for client /172.19.0.4:49348 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49348 (no session established for client)
Accepted socket connection from /172.19.0.4:49350
Refusing session request for client /172.19.0.4:49350 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49350 (no session established for client)
Getting Helix leader: 172.19.0.2_9000, Helix version: 0.9.8, mtime: 1608325163124
Accepted socket connection from /172.19.0.4:49352
Refusing session request for client /172.19.0.4:49352 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49352 (no session established for client)
Accepted socket connection from /172.19.0.4:49354
Refusing session request for client /172.19.0.4:49354 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49354 (no session established for client)
Accepted socket connection from /172.19.0.4:49356
Refusing session request for client /172.19.0.4:49356 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49356 (no session established for client)
Accepted socket connection from /172.19.0.4:49358
Refusing session request for client /172.19.0.4:49358 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49358 (no session established for client)
Accepted socket connection from /172.19.0.4:49360
Refusing session request for client /172.19.0.4:49360 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49360 (no session established for client)
Accepted socket connection from /172.19.0.4:49362
Refusing session request for client /172.19.0.4:49362 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49362 (no session established for client)
Accepted socket connection from /172.19.0.4:49364
Refusing session request for client /172.19.0.4:49364 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49364 (no session established for client)
Accepted socket connection from /172.19.0.4:49366
Refusing session request for client /172.19.0.4:49366 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49366 (no session established for client)
Accepted socket connection from /172.19.0.4:49368
Refusing session request for client /172.19.0.4:49368 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49368 (no session established for client)
Accepted socket connection from /172.19.0.4:49370
Refusing session request for client /172.19.0.4:49370 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49370 (no session established for client)
Accepted socket connection from /172.19.0.4:49372
Refusing session request for client /172.19.0.4:49372 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49372 (no session established for client)
Accepted socket connection from /172.19.0.4:49374
Refusing session request for client /172.19.0.4:49374 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49374 (no session established for client)
Accepted socket connection from /172.19.0.4:49376
Refusing session request for client /172.19.0.4:49376 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49376 (no session established for client)
Accepted socket connection from /172.19.0.4:49378
Refusing session request for client /172.19.0.4:49378 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49378 (no session established for client)
Accepted socket connection from /172.19.0.4:49380
Refusing session request for client /172.19.0.4:49380 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49380 (no session established for client)
Accepted socket connection from /172.19.0.4:49382
Refusing session request for client /172.19.0.4:49382 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49382 (no session established for client)
Accepted socket connection from /172.19.0.4:49384
Refusing session request for client /172.19.0.4:49384 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49384 (no session established for client)
Accepted socket connection from /172.19.0.4:49386
Refusing session request for client /172.19.0.4:49386 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49386 (no session established for client)
Accepted socket connection from /172.19.0.4:49388
Refusing session request for client /172.19.0.4:49388 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49388 (no session established for client)
Consumed 44 events from kafka stream meetupRSVPEvents (rate:0.7227451/s)
Accepted socket connection from /172.19.0.4:49390
Refusing session request for client /172.19.0.4:49390 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49390 (no session established for client)
Accepted socket connection from /172.19.0.4:49392
Refusing session request for client /172.19.0.4:49392 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49392 (no session established for client)
Accepted socket connection from /172.19.0.4:49394
Refusing session request for client /172.19.0.4:49394 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49394 (no session established for client)
Accepted socket connection from /172.19.0.4:49396
Refusing session request for client /172.19.0.4:49396 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49396 (no session established for client)
Accepted socket connection from /172.19.0.4:49398
Refusing session request for client /172.19.0.4:49398 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49398 (no session established for client)
Accepted socket connection from /172.19.0.4:49400
Refusing session request for client /172.19.0.4:49400 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49400 (no session established for client)
Accepted socket connection from /172.19.0.4:49402
Refusing session request for client /172.19.0.4:49402 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49402 (no session established for client)
Accepted socket connection from /172.19.0.4:49404
Refusing session request for client /172.19.0.4:49404 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49404 (no session established for client)
Accepted socket connection from /172.19.0.4:49406
Refusing session request for client /172.19.0.4:49406 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49406 (no session established for client)
Starting RealtimeSegmentValidationManager with running frequency of 3600 seconds.
Start running task: RealtimeSegmentValidationManager
Processing 1 tables in task: RealtimeSegmentValidationManager
Run segment-level validation
Finish processing 1/1 tables in task: RealtimeSegmentValidationManager
Finish running task: RealtimeSegmentValidationManager in 6ms
Accepted socket connection from /172.19.0.4:49408
Refusing session request for client /172.19.0.4:49408 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49408 (no session established for client)
Accepted socket connection from /172.19.0.4:49410
Refusing session request for client /172.19.0.4:49410 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49410 (no session established for client)
Accepted socket connection from /172.19.0.4:49412
Refusing session request for client /172.19.0.4:49412 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49412 (no session established for client)
Accepted socket connection from /172.19.0.4:49414
Refusing session request for client /172.19.0.4:49414 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49414 (no session established for client)
Accepted socket connection from /172.19.0.4:49416
Refusing session request for client /172.19.0.4:49416 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49416 (no session established for client)
Accepted socket connection from /172.19.0.4:49418
Refusing session request for client /172.19.0.4:49418 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49418 (no session established for client)
Accepted socket connection from /172.19.0.4:49420
Refusing session request for client /172.19.0.4:49420 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49420 (no session established for client)
Starting OfflineSegmentIntervalChecker with running frequency of 3600 seconds.
Start running task: OfflineSegmentIntervalChecker
Processing 1 tables in task: OfflineSegmentIntervalChecker
Finish processing 1/1 tables in task: OfflineSegmentIntervalChecker
Finish running task: OfflineSegmentIntervalChecker in 1ms
Accepted socket connection from /172.19.0.4:49422
Refusing session request for client /172.19.0.4:49422 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49422 (no session established for client)
Accepted socket connection from /172.19.0.4:49424
Refusing session request for client /172.19.0.4:49424 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49424 (no session established for client)
Accepted socket connection from /172.19.0.4:49426
Refusing session request for client /172.19.0.4:49426 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49426 (no session established for client)
Accepted socket connection from /172.19.0.4:49428
Refusing session request for client /172.19.0.4:49428 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49428 (no session established for client)
Getting Helix leader: 172.19.0.2_9000, Helix version: 0.9.8, mtime: 1608325163124
Accepted socket connection from /172.19.0.4:49430
Refusing session request for client /172.19.0.4:49430 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49430 (no session established for client)
Accepted socket connection from /172.19.0.4:49432
Refusing session request for client /172.19.0.4:49432 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49432 (no session established for client)
Accepted socket connection from /172.19.0.4:49434
Refusing session request for client /172.19.0.4:49434 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49434 (no session established for client)
Accepted socket connection from /172.19.0.4:49436
Refusing session request for client /172.19.0.4:49436 as it has seen zxid 0x478 our last zxid is 0x16c client must try another server
Closed socket connection for client /172.19.0.4:49436 (no session established for client)
